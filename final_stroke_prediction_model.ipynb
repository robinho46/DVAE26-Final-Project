{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0287e0e",
   "metadata": {},
   "source": [
    "## Stroke Prediction Project\n",
    "\n",
    "This notebook is my complete workflow for the Tabular Data project where i chose to work on Stroke Prediction, using structured data analysis, preprocessing, and machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93ce825",
   "metadata": {},
   "source": [
    "### Step 1: Import Libraries\n",
    "Start by importing the necessary libraries for data analysis and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7cf9ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data analysis and manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Profiling for detailed data analysis\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "# Suppress warnings for clean output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10571013",
   "metadata": {},
   "source": [
    "### Step 2: Load and Explore the Dataset\n",
    "Load the stroke dataset and perform an initial exploration to understand its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "65572447",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/stroke_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load dataset\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/stroke_data.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Display the first few rows\u001b[39;00m\n\u001b[1;32m      5\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/stroke_data.csv'"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('/stroke_data.csv')\n",
    "\n",
    "# Display the first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c1eb894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5110 entries, 0 to 5109\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   id                 5110 non-null   int64  \n",
      " 1   gender             5110 non-null   object \n",
      " 2   age                5110 non-null   float64\n",
      " 3   hypertension       5110 non-null   int64  \n",
      " 4   heart_disease      5110 non-null   int64  \n",
      " 5   ever_married       5110 non-null   object \n",
      " 6   work_type          5110 non-null   object \n",
      " 7   Residence_type     5110 non-null   object \n",
      " 8   avg_glucose_level  5110 non-null   float64\n",
      " 9   bmi                4909 non-null   float64\n",
      " 10  smoking_status     5110 non-null   object \n",
      " 11  stroke             5110 non-null   int64  \n",
      "dtypes: float64(3), int64(4), object(5)\n",
      "memory usage: 479.2+ KB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5be18a67846d409c921dd1be62617f2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "499e0388aeb34bddb022fe12ed508d00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a19b0b1696e4d8e86536a70da976ed2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed4a99e12d6e4e1c95ad039689cf4c05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dataset overview\n",
    "df.info()\n",
    "\n",
    "# Generate a profile report for detailed insights\n",
    "profile = ProfileReport(df, title=\"Stroke Data Profile\", explorative=True)\n",
    "profile.to_file(\"stroke_data_profile.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67965fef",
   "metadata": {},
   "source": [
    "### Step 3: Data Cleaning and Preprocessing\n",
    "To handle missing values, we encode categorical variables, and prepare the dataset for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a24f64f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>202.21</td>\n",
       "      <td>28.1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender   age  hypertension  heart_disease  ever_married  work_type  \\\n",
       "0       1  67.0             0              1             1          2   \n",
       "1       0  61.0             0              0             1          3   \n",
       "2       1  80.0             0              1             1          2   \n",
       "3       0  49.0             0              0             1          2   \n",
       "4       0  79.0             1              0             1          3   \n",
       "\n",
       "   Residence_type  avg_glucose_level   bmi  smoking_status  stroke  \n",
       "0               1             228.69  36.6               1       1  \n",
       "1               0             202.21  28.1               2       1  \n",
       "2               0             105.92  32.5               2       1  \n",
       "3               1             171.23  34.4               3       1  \n",
       "4               0             174.12  24.0               2       1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop irrelevant columns (e.g., 'id')\n",
    "df.drop(['id'], axis=1, inplace=True)\n",
    "\n",
    "# Handle missing values in BMI by imputing with the median\n",
    "df['bmi'].fillna(df['bmi'].median(), inplace=True)\n",
    "\n",
    "# Encode categorical variables using label encoding\n",
    "categorical_columns = ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoders = {}\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Remove duplicates\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Display the cleaned dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c1aea0",
   "metadata": {},
   "source": [
    "### Step 4: Exploratory Data Analysis (EDA)\n",
    "Visualize data distributions and relationships to gain insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b36f36b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of the target variable\n",
    "sns.countplot(x='stroke', data=df)\n",
    "plt.title(\"Distribution of Stroke Outcomes\")\n",
    "plt.show()\n",
    "\n",
    "# Correlation heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f14215a",
   "metadata": {},
   "source": [
    "### Step 5: Model Development\n",
    "We build, train, and evaluate machine learning models for stroke prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c2ea60b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9406924922865958\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94      1457\n",
      "           1       0.92      0.96      0.94      1460\n",
      "\n",
      "    accuracy                           0.94      2917\n",
      "   macro avg       0.94      0.94      0.94      2917\n",
      "weighted avg       0.94      0.94      0.94      2917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data into features and target\n",
    "X = df.drop('stroke', axis=1)\n",
    "y = df['stroke']\n",
    "\n",
    "# Apply SMOTE to handle class imbalance\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Split into train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train a Random Forest model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769d5777",
   "metadata": {},
   "source": [
    "### Step 6: Save the Model\n",
    "Save the trained model and preprocessing pipelines for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b67825e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and encoders saved!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model, \"stroke_model.pkl\")\n",
    "\n",
    "# Save the label encoders\n",
    "for col, le in label_encoders.items():\n",
    "    joblib.dump(le, f\"{col}_encoder.pkl\")\n",
    "\n",
    "print(\"Model and encoders saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a6234a27-2a7f-4076-9f62-665e7af10b5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['smoking_status_encoder.pkl']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "\n",
    "# Create and save encoders with all expected categories\n",
    "le_gender = LabelEncoder()\n",
    "le_gender.fit(['Male', 'Female'])\n",
    "joblib.dump(le_gender, \"gender_encoder.pkl\")\n",
    "\n",
    "le_ever_married = LabelEncoder()\n",
    "le_ever_married.fit(['No', 'Yes'])\n",
    "joblib.dump(le_ever_married, \"ever_married_encoder.pkl\")\n",
    "\n",
    "le_work_type = LabelEncoder()\n",
    "le_work_type.fit(['Private', 'Self-employed', 'Govt_job', 'children', 'Never_worked'])\n",
    "joblib.dump(le_work_type, \"work_type_encoder.pkl\")\n",
    "\n",
    "le_residence_type = LabelEncoder()\n",
    "le_residence_type.fit(['Urban', 'Rural'])\n",
    "joblib.dump(le_residence_type, \"residence_type_encoder.pkl\")\n",
    "\n",
    "le_smoking_status = LabelEncoder()\n",
    "le_smoking_status.fit(['never smoked', 'formerly smoked', 'smokes', 'Unknown'])\n",
    "joblib.dump(le_smoking_status, \"smoking_status_encoder.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdddf98",
   "metadata": {},
   "source": [
    "## Step 7: Preprocessing and Unit Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "baf4f241",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def preprocess_data(data):\n",
    "    # Create LabelEncoders\n",
    "    label_encoders = {}\n",
    "    categorical_columns = ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']\n",
    "    \n",
    "    # Impute missing BMI values\n",
    "    data['bmi'].fillna(data['bmi'].median(), inplace=True)\n",
    "    \n",
    "    # Encode categorical columns\n",
    "    for col in categorical_columns:\n",
    "        le = LabelEncoder()\n",
    "        data[col] = le.fit_transform(data[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "        \n",
    "    return data, label_encoders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9b06d001",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_label_encoding (__main__.TestPreprocessing.test_label_encoding) ... ok\n",
      "test_missing_values (__main__.TestPreprocessing.test_missing_values) ... /tmp/ipykernel_40285/2989116098.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['bmi'].fillna(data['bmi'].median(), inplace=True)\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.015s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import unittest\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class TestPreprocessing(unittest.TestCase):\n",
    "    \n",
    "    def setUp(self):\n",
    "        data = {\n",
    "            \"gender\": [\"Male\", \"Female\", \"Male\"],\n",
    "            \"age\": [34, 45, 29],\n",
    "            \"hypertension\": [0, 1, 0],\n",
    "            \"heart_disease\": [0, 0, 1],\n",
    "            \"ever_married\": [\"Yes\", \"No\", \"Yes\"],\n",
    "            \"work_type\": [\"Private\", \"Self-employed\", \"Private\"],\n",
    "            \"Residence_type\": [\"Urban\", \"Rural\", \"Urban\"],\n",
    "            \"avg_glucose_level\": [120.0, 140.5, 130.0],\n",
    "            \"bmi\": [24.5, 25.5, np.nan],\n",
    "            \"smoking_status\": [\"never smoked\", \"smokes\", \"never smoked\"]\n",
    "        }\n",
    "        self.df = pd.DataFrame(data)\n",
    "\n",
    "    def test_missing_values(self):\n",
    "        self.assertTrue(self.df.isnull().values.any(), \"Missing values are not found.\")\n",
    "        processed_data, _ = preprocess_data(self.df)\n",
    "        self.assertFalse(processed_data.isnull().any().any(), \"Missing values found after preprocessing.\")\n",
    "\n",
    "    def test_label_encoding(self):\n",
    "        label_encoder = LabelEncoder()\n",
    "        encoded_df = self.df.copy()\n",
    "        for column in ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']:\n",
    "            encoded_df[column] = label_encoder.fit_transform(self.df[column])\n",
    "        for column in ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']:\n",
    "            self.assertTrue(pd.api.types.is_integer_dtype(encoded_df[column]), f\"Column {column} is not encoded correctly.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=[''], verbosity=2, exit=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a24a4d",
   "metadata": {},
   "source": [
    "### Step 8: Deployment with Gradio\n",
    "Create an interactive interface for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8346d556-893d-419f-a3e3-ac24a7197d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in /home/robin/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (0.27.0)\n",
      "Requirement already satisfied: filelock in /home/robin/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from huggingface_hub) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/robin/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from huggingface_hub) (2024.12.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/robin/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from huggingface_hub) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/robin/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in /home/robin/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/robin/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from huggingface_hub) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/robin/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/robin/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from requests->huggingface_hub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/robin/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from requests->huggingface_hub) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/robin/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from requests->huggingface_hub) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/robin/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from requests->huggingface_hub) (2024.7.4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07869ddde1694ceca6adada5325f86e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install huggingface_hub\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()\n",
    "#checkout git\n",
    "#login to huggingface, setting, access token, generate a new token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "84fc1300-d7eb-431b-bf76-1765507356bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2a638a227ae43f0b2c4d548fa5a6493",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df808c405a394005aeff8e7926b6395d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "stroke_model.pkl:   0%|          | 0.00/11.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model uploaded successfully to: https://huggingface.co/robinho46/Project\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "# Log in to Hugging Face (interactive method)\n",
    "notebook_login()\n",
    "\n",
    "# Path to your model file\n",
    "model_path = \"stroke_model.pkl\"\n",
    "\n",
    "# Upload the model to the repository\n",
    "from huggingface_hub import upload_file\n",
    "\n",
    "upload_file(\n",
    "    path_or_fileobj=model_path,  # Path to the model file\n",
    "    path_in_repo=\"stroke_model.pkl\",  # The file name you want in the repo\n",
    "    repo_id=\"robinho46/Project\",  # Your Hugging Face repo\n",
    "    token=None  # No need to pass the token if you're using notebook_login()\n",
    ")\n",
    "\n",
    "print(f\"Model uploaded successfully to: https://huggingface.co/robinho46/Project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bda6860c-8fe5-445e-84bc-aa6e69a956f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import upload_file\n",
    "\n",
    "# Directly authenticate using the token\n",
    "hf_token = \"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\"  # Your Hugging Face token\n",
    "\n",
    "# Path to your model file\n",
    "model_path = \"stroke_model.pkl\"\n",
    "\n",
    "# Upload the model to the repository\n",
    "upload_file(\n",
    "    path_or_fileobj=model_path,  # Path to the model file\n",
    "    path_in_repo=\"stroke_model.pkl\",  # The file name you want in the repo\n",
    "    repo_id=\"robinho46/Project\",  # Your Hugging Face repo\n",
    "    token=hf_token  # Pass the token directly\n",
    ")\n",
    "\n",
    "print(f\"Model uploaded successfully to: https://huggingface.co/robinho46/Project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3b1d7782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and update encoders globally once\n",
    "def load_and_update_encoders():\n",
    "    encoders = {\n",
    "        \"gender\": joblib.load(\"gender_encoder.pkl\"),\n",
    "        \"ever_married\": joblib.load(\"ever_married_encoder.pkl\"),\n",
    "        \"work_type\": joblib.load(\"work_type_encoder.pkl\"),\n",
    "        \"Residence_type\": joblib.load(\"residence_type_encoder.pkl\"),\n",
    "        \"smoking_status\": joblib.load(\"smoking_status_encoder.pkl\"),\n",
    "    }\n",
    "    # Ensure all necessary classes are included\n",
    "    for category, default in zip(\n",
    "        ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status'],\n",
    "        ['Female', 'No', 'Private', 'Urban', 'Unknown']\n",
    "    ):\n",
    "        if default not in encoders[category].classes_:\n",
    "            encoders[category].classes_ = np.append(encoders[category].classes_, default)\n",
    "    return encoders\n",
    "\n",
    "# Load and update encoders globally\n",
    "encoders = load_and_update_encoders()\n",
    "\n",
    "# Define the prediction function\n",
    "def predict_stroke(gender, age, hypertension, heart_disease, ever_married, work_type, Residence_type, avg_glucose_level, bmi, smoking_status):\n",
    "    # Encode inputs\n",
    "    data = pd.DataFrame([{\n",
    "        'gender': encoders['gender'].transform([gender])[0],\n",
    "        'age': age,\n",
    "        'hypertension': hypertension,\n",
    "        'heart_disease': heart_disease,\n",
    "        'ever_married': encoders['ever_married'].transform([ever_married])[0],\n",
    "        'work_type': encoders['work_type'].transform([work_type])[0],\n",
    "        'Residence_type': encoders['Residence_type'].transform([Residence_type])[0],\n",
    "        'avg_glucose_level': avg_glucose_level,\n",
    "        'bmi': bmi,\n",
    "        'smoking_status': encoders['smoking_status'].transform([smoking_status])[0],\n",
    "    }])\n",
    "\n",
    "    # Make prediction\n",
    "    prediction = model.predict(data)[0]\n",
    "    return \"Stroke\" if prediction == 1 else \"No Stroke\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "48cf58ac-3a83-4e57-9656-5a28bccfbb0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# Create Gradio interface\n",
    "interface = gr.Interface(\n",
    "    fn=predict_stroke,  # The function to handle predictions\n",
    "    inputs=[\n",
    "        gr.Radio([\"Male\", \"Female\"], label=\"Gender\"),\n",
    "        gr.Number(label=\"Age\"),\n",
    "        gr.Radio([0, 1], label=\"Hypertension (0: No, 1: Yes)\"),\n",
    "        gr.Radio([0, 1], label=\"Heart Disease (0: No, 1: Yes)\"),\n",
    "        gr.Radio([\"No\", \"Yes\"], label=\"Ever Married\"),\n",
    "        gr.Dropdown([\"Private\", \"Self-employed\", \"Govt_job\", \"children\", \"Never_worked\"], label=\"Work Type\"),\n",
    "        gr.Dropdown([\"Urban\", \"Rural\"], label=\"Residence Type\"),\n",
    "        gr.Number(label=\"Average Glucose Level\"),\n",
    "        gr.Number(label=\"BMI\"),\n",
    "        gr.Dropdown([\"never smoked\", \"formerly smoked\", \"smokes\", \"Unknown\"], label=\"Smoking Status\"),\n",
    "    ],\n",
    "    outputs=gr.Textbox(label=\"Prediction\"),\n",
    "    title=\"Stroke Prediction\",\n",
    ")\n",
    "\n",
    "# Launch the Gradio interface\n",
    "interface.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
